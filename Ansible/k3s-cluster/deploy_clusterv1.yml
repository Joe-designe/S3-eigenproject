---
# ==============================================================================
# FASE 1: K3s INSTALLATIE
# ==============================================================================

- name: 1. Installeer K3s Master
  hosts: server
  become: true
  tasks:
    - name: Download en installeer K3s (Master)
      shell: curl -sfL https://get.k3s.io | sh -
      args:
        creates: /usr/local/bin/k3s

    - name: Wacht tot K3s start
      wait_for:
        port: 6443
        delay: 5
        timeout: 300

    - name: Haal node-token op (voor workers)
      slurp:
        src: /var/lib/rancher/k3s/server/node-token
      register: k3s_token_base64

    - name: Stel token vast
      set_fact:
        k3s_token: "{{ k3s_token_base64['content'] | b64decode | trim }}"

- name: 2. Installeer K3s Workers
  hosts: agent
  become: true
  tasks:
    - name: Join het cluster
      shell: "curl -sfL https://get.k3s.io | K3S_URL=https://{{ hostvars[groups['server'][0]]['inventory_hostname'] }}:6443 K3S_TOKEN={{ hostvars[groups['server'][0]]['k3s_token'] }} sh -"
      args:
        creates: /usr/local/bin/k3s-agent

# ==============================================================================
# FASE 2: CONFIGURATIE LOCALHOST (ANSIBLE VM)
# ==============================================================================

- name: 3. Configureer Ansible VM en haal Config op
  hosts: server
  become: true
  tasks:
    # Dit haalt het bestand van de SERVER naar je ANSIBLE VM
    - name: Haal kubeconfig op naar Ansible VM
      fetch:
        src: /etc/rancher/k3s/k3s.yaml
        dest: ~/.kube/config
        flat: yes

- name: 4. Configureer lokaal kubectl (Ansible VM)
  hosts: localhost
  connection: local
  gather_facts: false # uit voor snelheid, we zetten het later aan voor Argo
  tasks:
    - name: Download en installeer kubectl binary
      become: true
      get_url:
        url: "https://dl.k8s.io/release/v1.32.0/bin/linux/amd64/kubectl"
        dest: /usr/local/bin/kubectl
        mode: '0755'

    - name: Maak .kube map aan in home directory
      file:
        path: ~/.kube
        state: directory
        mode: '0700'
    
    - name: Pas rechten aan van config
      file:
        path: ~/.kube/config
        mode: '0600'

    - name: Wijzig 127.0.0.1 naar het echte Master IP
      replace:
        path: ~/.kube/config
        regexp: 'https://127.0.0.1:6443'
        replace: "https://{{ hostvars[groups['server'][0]]['ansible_host'] | default(groups['server'][0]) }}:6443"

# ==============================================================================
# FASE 3: ARGOCD & APPS UITROLLEN
# ==============================================================================

- name: 5. Installeer ArgoCD en Bootstrap Cluster
  hosts: localhost
  connection: local
  gather_facts: true # NODIG voor ansible_env.HOME
  tasks:
    - name: Maak ArgoCD namespace aan
      kubernetes.core.k8s:
        name: argocd
        api_version: v1
        kind: Namespace
        state: present
        kubeconfig: "{{ ansible_env.HOME }}/.kube/config"

    - name: Download en installeer ArgoCD (Core installatie)
      kubernetes.core.k8s:
        state: present
        src: https://raw.githubusercontent.com/argoproj/argo-cd/v3.2.1/manifests/install.yaml
        namespace: argocd
        kubeconfig: "{{ ansible_env.HOME }}/.kube/config"

    - name: Wacht tot ArgoCD pods starten 
      shell: kubectl wait --for=condition=Available deployment/argocd-server -n argocd --timeout=300s
      environment:
        KUBECONFIG: "{{ ansible_env.HOME }}/.kube/config"

    - name: Patch ArgoCD service naar LoadBalancer 
      shell: |
        kubectl patch svc argocd-server -n argocd -p '{"spec": {"type": "LoadBalancer"}}'
      environment:
        KUBECONFIG: "{{ ansible_env.HOME }}/.kube/config"

    # --- De Longhorn voorbereiding ---
    - name: "[FIX] Maak Longhorn namespace aan"
      kubernetes.core.k8s:
        name: longhorn-system
        api_version: v1
        kind: Namespace
        state: present
        kubeconfig: "{{ ansible_env.HOME }}/.kube/config"

    - name: "[FIX] Maak Longhorn ServiceAccount aan"
      kubernetes.core.k8s:
        state: present
        kubeconfig: "{{ ansible_env.HOME }}/.kube/config"
        definition:
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: longhorn-service-account
            namespace: longhorn-system

    - name: "[FIX] Maak Longhorn ClusterRoleBinding aan"
      kubernetes.core.k8s:
        state: present
        kubeconfig: "{{ ansible_env.HOME }}/.kube/config"
        definition:
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: longhorn-service-account-fix
          subjects:
          - kind: ServiceAccount
            name: longhorn-service-account
            namespace: longhorn-system
          roleRef:
            kind: ClusterRole
            name: cluster-admin
            apiGroup: rbac.authorization.k8s.io

    # --- De Bootstrap Stap ---
    - name: Apply Root App (Bootstrap het cluster)
      command: kubectl apply -f https://raw.githubusercontent.com/Joe-designe/S3-eigenproject/main/Cluster/root-app.yaml
      environment:
        KUBECONFIG: "{{ ansible_env.HOME }}/.kube/config"

# ==============================================================================
# FASE 4: BEVEILIGING (FIREWALL / HARDENING) - ALS LAATSTE!
# ==============================================================================

- name: 6. Configureer Firewall (UFW) voor K3s Cluster
  hosts: k3s_cluster
  become: true
  vars:
    trusted_subnet: "192.168.124.0/24"  # Pas aan indien nodig

  tasks:
    - name: Zorg dat UFW is ge√Ønstalleerd
      apt:
        name: ufw
        state: present

    - name: Zet standaard beleid op deny (inkomend)
      community.general.ufw:
        direction: incoming
        policy: deny

    - name: Zet logging aan
      community.general.ufw:
        logging: 'on'

    - name: Sta SSH toe (Poort 22)
      community.general.ufw:
        rule: allow
        port: '22'
        proto: tcp
        comment: "SSH toegang voor beheer"

    - name: Sta al het verkeer toe vanuit het interne subnet
      community.general.ufw:
        rule: allow
        src: "{{ trusted_subnet }}"
        comment: "Cluster nodes volledig vertrouwen"

    - name: Sta HTTP (80) toe
      community.general.ufw:
        rule: allow
        port: '80'
        proto: tcp
        comment: "Traefik Ingress HTTP"

    - name: Sta HTTPS (443) toe
      community.general.ufw:
        rule: allow
        port: '443'
        proto: tcp
        comment: "Traefik Ingress HTTPS"

    - name: Sta Portainer NodePort/LB toe (9443)
      community.general.ufw:
        rule: allow
        port: '9443'
        proto: tcp
        comment: "Portainer Direct Access"

    - name: Sta Kubernetes API toe (Alleen op Master)
      community.general.ufw:
        rule: allow
        port: '6443'
        proto: tcp
        comment: "K3s API Server"
      when: "'server' in group_names"

    - name: Enable UFW en start direct
      community.general.ufw:
        state: enabled

# ==============================================================================
# FASE 5: BEVEILIGING ANSIBLE CONTROL NODE
# ==============================================================================

- name: 7. Configureer Firewall voor Ansible Control Node
  hosts: localhost
  connection: local
  become: true
  tasks:
    - name: Zorg dat UFW is ge√Ønstalleerd
      apt:
        name: ufw
        state: present

    - name: Zet standaard incoming op deny
      community.general.ufw:
        direction: incoming
        policy: deny

    - name: Zet standaard outgoing op allow
      community.general.ufw:
        direction: outgoing
        policy: allow

    - name: Sta SSH toe (Voor beheerder)
      community.general.ufw:
        rule: allow
        port: '22'
        proto: tcp
        comment: "SSH toegang voor beheerder"

    - name: Enable UFW op Ansible VM
      community.general.ufw:
        state: enabled

# ==============================================================================
# FASE 6: AFRONDING & INFO
# ==============================================================================

- name: 8. Toon eindresultaat
  hosts: localhost
  connection: local
  gather_facts: false
  tasks:
    - name: Haal ArgoCD admin wachtwoord op
      shell: kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
      environment:
        KUBECONFIG: "{{ ansible_env.HOME }}/.kube/config"
      register: argocd_password

    - name: Toon inloggegevens
      debug:
        msg: 
          - "=============================================="
          - "üöÄ INSTALLATIE & HARDENING SUCCESVOL!"
          - "=============================================="
          - "ArgoCD User: admin"
          - "ArgoCD Pass: {{ argocd_password.stdout }}"
          - "----------------------------------------------"
          - "üõ°Ô∏è  Beveiliging:"
          - "Firewall is actief op alle nodes & Ansible VM."
          - "----------------------------------------------"
          - "Dashboard URL's:"
          - "  - https://argocd.demo.local"
          - "  - https://longhorn.demo.local"
          - "  - https://grafana.demo.local"
          - "  - https://portainer.demo.local"
          - "=============================================="